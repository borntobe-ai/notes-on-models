# Buzz Words

English | [简体中文](./index_zh-CN.md)

**Gradient**: A gradient measures how much the output of a function changes if you change the inputs a little bit. It is a vector of partial derivatives with respect to all input variables. Gradients are used in optimization algorithms, such as gradient descent, to minimize the loss function by iteratively adjusting the model parameters in the direction that reduces the error.

**Loss Function**: A loss function measures how well a machine learning model's predictions match the actual data. It quantifies the difference between the predicted values and the true values. The goal of training a model is to minimize the loss function, thereby improving the model's accuracy.

**Pre-Train**: Pre-training is the process of training a model on a large dataset before fine-tuning it for a specific task. This initial training phase allows the model to learn general features and patterns from a broad range of data, establishing a foundation of knowledge that can be transferred to more specialized tasks. Pre-training is particularly important in deep learning models like transformers, where models like BERT, GPT, and others are first trained on massive text corpora to learn language representations before being fine-tuned for specific applications such as question answering, sentiment analysis, or text generation. This approach significantly reduces the amount of task-specific data needed and improves performance on downstream tasks.

**Fine Tune**: Fine-tuning is the process of making small adjustments to a pre-trained machine learning model to adapt it to a specific task or dataset. This involves training the model on a new, often smaller, dataset for a few more epochs, allowing it to learn the nuances of the new data while retaining the general knowledge it acquired during the initial training phase. Fine-tuning is commonly used in transfer learning to improve model performance on specialized tasks.

**Tensor**: A tensor is a multi-dimensional array that generalizes the concept of scalars (0D), vectors (1D), and matrices (2D) to higher dimensions. Tensors are used to represent data in various forms, such as input data, weights, and activations in neural networks. They are a fundamental data structure in machine learning frameworks like TensorFlow and PyTorch, enabling efficient computation and manipulation of large-scale data.

**Hyperparameters**: Hyperparameters are the configuration settings used to structure and train a model. Unlike model parameters, which are learned during training, hyperparameters are set before the training process begins. Examples include the learning rate, batch size, number of epochs, and the architecture of the neural network (such as the number of layers and units per layer). Proper tuning of hyperparameters is crucial for optimizing model performance and achieving the best possible results.

**Optimizer**: An optimizer in machine learning, particularly in the context of neural networks, is an algorithm or method used to adjust the parameters (weights and biases) of the model to minimize the loss function. The goal of the optimizer is to find the set of parameters that result in the best performance of the model on the given task.

**Reinforcement Learning**: Reinforcement Learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize some notion of cumulative reward. The agent learns through trial and error, receiving feedback in the form of rewards or penalties. Unlike supervised learning, the agent is not told which actions to take, but instead must discover which actions yield the highest reward by exploring the environment. Key components include the agent (the decision-maker), the environment (what the agent interacts with), actions (what the agent can do), states (situations the agent finds itself in), and rewards (feedback from the environment). Reinforcement Learning is used in various applications such as game playing, robotics, autonomous vehicles, and recommendation systems.
